# -*- coding: utf-8 -*-
"""Clean_Undirectional_Social_Media.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T5vYSOAoKEZ1ZqqEgvTyoqXjOgN3aPdH

### Initialization :

Mount Google Drive on colab
"""

from google.colab import drive
drive.mount('/content/drive')

"""Import required modules"""

import networkx as nx
from datetime import *
import sqlite3
import matplotlib.pyplot as plt
from collections import defaultdict
import numpy as np
import seaborn as sns
import pandas as pd
from scipy.optimize import curve_fit

"""### Plot functions :

Plot a graph
"""

def plot_graph(graph, node_size=60) -> None:
    nx.draw(graph, with_labels=False, node_size=node_size)
    plt.figure(3, figsize=(12, 12))
    plt.show()

"""Plot degree distribution """

def plot_degree_histogram(description: dict):
  plt.hist(description['degree_distribution_of_vertices'])
  plt.show()

"""Plot communities size"""

def plot_communities_size_histogram(description: dict):
  plt.hist(description['communities_size'])
  plt.show()

"""Plot tree hierarchy with given information"""

def plot_tree_hierarchy(information: dict):
  trees = []
  for key in information.keys():
    if information[key][1] != float('inf'):
      trees.append(information[key][1])
  plt.plot(trees)
  plt.show()

"""Plot leaf numbers of given information"""

def plot_leaf_numbers(information: dict):
  leaf_numbers = []
  for key in information.keys():
    if information[key][0] != float('inf'):
      leaf_numbers.append(information[key][0])
  plt.plot(leaf_numbers)
  plt.show()

"""Plot a feature in a specific time line"""

def plot_features_year_to_year(year_description: dict, feature_name:str) -> None:
  years = [year for year in year_description.keys()]
  features = [year_description[year][feature_name] for year in years]
  plt.plot(years, features)
  plt.grid()
  plt.xlabel('Years')
  plt.ylabel(feature_name)
  plt.show()
  if feature_name == 'number_of_nodes' or feature_name == 'number_of_edges' or feature_name == 'weights_sum':
      new_years = []
      for i in range(len(years) - 1):
          new_years.append(str(years[i]) + '-'+ str(years[i+1]))
      new_features = np.diff(features)
      plt.plot(new_years, new_features)
      plt.grid()
      plt.xlabel("Years")
      plt.ylabel("Differentiation of " + feature_name)
      plt.show()

"""Plot ditribution of an array"""

def plot_distribution(arr) -> None:
  plt.hist(arr)
  plt.show()

"""Plot specific feature over time in scatter mode with quadratic polynomial fitted curve"""

def plot_features_year_to_year_scatter(year_description: dict, feature_name: str) -> None:
    years = [year for year in year_description.keys()]
    features = [year_description[year][feature_name] for year in years]
    plt.scatter(years, features)
    plt.grid()
    plt.xlabel('Years')
    plt.ylabel(feature_name)
    coef = np.polyfit(years, features, 2)
    print(coef)
    new_x = np.linspace(min(years), max(years), num=np.size(years) * 100)
    new_line = np.polyval(coef, new_x)
    plt.scatter(new_x,new_line,c='g', marker='^', s=5)
    plt.xlabel("years")
    plt.ylabel(feature_name)
    plt.show()

"""Plot features year to year with exponential fitted curve"""

def plot_features_year_to_year_expo(year_description: dict, feature_name: str) -> None:
    years = [year for year in year_description.keys()]
    features = [year_description[year][feature_name] for year in years]
    plt.scatter(years, features)
    plt.grid()
    plt.xlabel('Years')
    plt.ylabel(feature_name)
    popt, pcov = curve_fit(lambda t, a, b, c: a * np.exp(b * t) + c, years, features)
    a = popt[0]
    b = popt[1]
    c = popt[2]
    print('a =', a)
    print('b =', b)
    print('c =', c)
    new_x = np.linspace(min(years), max(years), num=np.size(years) * 100)
    new_fun = a * np.exp(b * new_x) + c
    plt.plot(new_x, new_fun, 'k', label='Fitted curve')
    plt.legend()
    plt.xlabel('years')
    plt.ylabel(feature_name)
    plt.show()

"""Plot a specific feature in years for comparison"""

def plot_features_year_to_year_scatter_comparison(year_description1: dict, year_description2:dict, feature_name: str) -> None:
    years1 = [year for year in year_description1.keys()]
    features1 = [year_description1[year][feature_name] for year in years1]
    years2 = [year for year in year_description2.keys()]
    features2 = [year_description2[year][feature_name] for year in years2]
    plt.scatter(years1, features1, c='b')
    plt.scatter(years2, features2, c='r')
    coef1 = np.polyfit(years1, features1, 2)
    coef2 = np.polyfit(years2, features2, 2)
    print("First group coefficients:",coef1)
    print("Second group coefficients:", coef2)
    new_x1 = np.linspace(min(years1), max(years1), num=np.size(years1) * 100)
    new_line1 = np.polyval(coef1, new_x1)
    new_x2 = np.linspace(min(years2), max(years2), num=np.size(years2) * 100)
    new_line2 = np.polyval(coef2, new_x2)
    plt.scatter(new_x1,new_line1,c='darkblue', marker='^', s=5)
    plt.scatter(new_x2, new_line2, c="darkred", marker='^', s=5)
    plt.xlabel("years")
    plt.ylabel(feature_name)
    plt.legend(['First group actual data','Second group actual data', 'First group fitted curve', 'Second group fitted curve'])
    plt.show()

"""Plot 4D figure for questions"""

def plot_4D_Questions(data_frame: pd.DataFrame) -> None:
    sns.set_theme(style="white")
    cmap = sns.color_palette("ch:s=.25,rot=-.25", as_cmap=True)
    rel_plot = sns.relplot(x="Days", y="Duration", size="Comments number", hue="Question Visit",
                sizes=(40, 400), alpha=.8, palette=cmap,
                height=10, data=data_frame)
    plt.grid()
    plt.show()

"""Plot 4D figure for users"""

def plot_4D_Users(data_frame: pd.DataFrame) -> None:
    sns.set_theme(style="white")
    cmap = sns.color_palette("ch:s=.25,rot=-.25", as_cmap=True)
    rel_plot = sns.relplot(x="First Activity(Day)", y="Last - First activity(Day)", size="Post counts",
                sizes=(40, 400), alpha=.8, palette=cmap,
                height=10, data=data_frame)
    plt.grid()
    plt.show()

def plot_degree_distribution(description: dict) -> None:
    summation = sum(description['degree_distribution_of_vertices'])
    arr = [description['degree_distribution_of_vertices'][i]/summation for i in range(len(description['degree_distribution_of_vertices']))]
    plt.hist(arr)
    plt.show()

def plot_communities_distribution(description: dict) -> None:
    summation = sum(description['communities_size'])
    arr = [description['communities_size'][i] / summation for i in range(len(description['communities_size']))]
    plt.hist(arr)
    plt.show()

"""### User, Question, Comment and ResultData classes and functions:

This function convert string format of date in comments and questions to datetime object in python
"""

def stringToDate_posts(date_str: str):
    try:
      # For majority class of data: yyyy/mm/dd HH:MM
      li = date_str.split()
      date = li[0]
      time = li[1]
      date = date.split('/')
      time = time.split(":")
      year = int(date[0])
      month = int(date[1])
      day = int(date[2])
      if day > 28:
        day -= 3
      hour = int(time[0])
      minute = int(time[1])
      answer = datetime(2018, 6, 1)
      answer = answer.replace(year=year, month=month, day=day, hour=hour, minute=minute)
    except:
      # For some misvalues 
      li = date_str.split()
      day_name = li[0]
      month = li[1]
      day = int(li[2])
      ti = li[3].split(':')
      hour = int(ti[0])
      minute = int(ti[1])
      year = int(li[5])
      answer = datetime(2018, 6, 1)
      answer = answer.replace(year=year, month=1, hour=hour, minute=minute)
    return answer

"""This function converts string format of date in users' signUpDate to datetime object in python """

def stringToDate_users(date_str: str):
    li = date_str.split()
    day = int(li[2])
    month = int(li[3].split(":")[1])
    year = int(li[5])
    answer = datetime(2018, 6, 1)
    if day >= 29:
        day -= 5
    answer = answer.replace(year=year, month=month, day=day)
    return answer

"""This function returns day difference between given time and start time"""

def dateTime_to_int(time: datetime, start_time: datetime) -> int:
    # This method get's time and start_time and returns number of days in difference
    year_diff = time.year - start_time.year
    month_diff = time.month - start_time.month
    day_diff = time.day - start_time.day
    answer = year_diff * 365 + month_diff * 30 + day_diff
    return answer

"""Question class"""

class Question:
    def __init__(self, QID: str, QUserID: str, QTitle: str, QBody: str, QDate: str, QVisit: int):
        self.QID = QID
        self.QUserID = QUserID
        self.QBody = QBody
        self.QTitle = QTitle
        self.QDate = stringToDate_posts(QDate)
        self.QVisit = QVisit

    def __repr__(self):
        return "[QID : {0}, QUserID : {1}, QTitle : {2}, QDate : {3}, QVisit : {4}]".format(self.QID, self.QUserID,
                                                                                            self.QTitle, self.QDate,
                                                                                            self.QVisit)

    # def __eq__(self, other):
    # return self.QID == other.QID

"""User class"""

class User:
    def __init__(self, UserID: str, Username: str, Description: str, SignUpDate: str, PostCount: int):
        self.UserID = UserID
        self.Username = Username
        self.Description = Description
        self.SignUpDate = stringToDate_users(SignUpDate)
        self.PostCount = PostCount

    def __repr__(self):
        print(self.UserID)
        return "[UserID : {0}, Username : {1}, Description : {2}, SignUpDate : {3}, PostCount : {4}]".format(
            self.UserID, self.Username, self.Description, self.SignUpDate, self.PostCount)

    # def __eq__(self, other):
    # return self.UserID == other.UserID

"""Comment class"""

class Comment:
    def __init__(self, CID: str, QID: str, CUserID: str, CBody: str, CDate: str, isReply: bool, ParentID: str):
        self.CID = CID
        self.QID = QID
        self.CUserID = CUserID
        self.CBody = CBody
        self.CDate = stringToDate_posts(CDate)
        self.isReply = isReply
        self.ParentID = ParentID

    def __repr__(self):
        return "[CID: {}, QID : {}, CUserID : {}, CBody : {}, CDate : {}, isReply : {}, ParentID : {}]".format(self.CID,
                                                                                                               self.QID,
                                                                                                               self.CUserID,
                                                                                                               self.CBody,
                                                                                                               self.CDate,
                                                                                                               self.isReply,
                                                                                                               self.ParentID)

    # def __eq__(self, other):
    # return self.CID == other.CID

"""ResultData class which handle ExportData table in database"""

class ResultData:
    def __init__(self, QID: str, QUserID: str, QTitle: str, QBody: str, QDate: str, QVisit: int, CID: str, CUserID: str,
                 CBody: str, CDate: str, isReply: bool, ParentID: str):
        self.QID = QID
        self.QUserID = QUserID
        self.QTitle = QTitle
        self.QBody = QBody
        self.QDate = stringToDate_posts(QDate)
        self.QVisit = QVisit
        self.CID = CID
        self.CUserID = CUserID
        self.CBody = CBody
        self.CDate = stringToDate_posts(CDate)
        self.isReply = isReply
        self.ParentID = ParentID

    def __repr__(self):
        return "[QID: {}, QUserID: {}, QTitle: {}, QBody: {}, QDate: {}, QVisit: {}, CID: {}, CUserID: {}, CBody: {}, CDate: {}, isReply: {}, ParentID: {}]".format(
            self.QID, self.QUserID, self.QTitle, self.QBody, self.QDate, self.QVisit, self.CID, self.CUserID,
            self.CBody, self.CDate, self.isReply, self.ParentID)

    # def __eq__(self, other):
    # return self.CID == other.CID

"""### GraphAnalysis class and functions :

Features names
"""

features_names = ['number_of_nodes', 'number_of_edges', 'edges', 'weights_sum', 'is_connected', 'number_connected_components', 'connected_components', 'global_efficiency', 'local_efficiency', 'graph_clustering', 'nodes_info', 'degree_distribution_of_vertices', 'communities_size', 'degree_centrality', 'betweenness_centrality', 'closeness_centrality', 'average_shortest_path_length', 'tree_hierarchy', 'small_worldness_omega', 'small_worldness_sigma', 'transitivity', 'diameter']

"""\begin{align}
\text{Weight manipulation formula: } &W_2 = \frac{1}{W_1}
\end{align}
"""

def weight_manipulation_function(weight: float)->float:
  return 1 / weight

"""This function reweight a graph with respect to weight_manipulation_function"""

def reweight_graph(graph) -> nx.Graph:
  answer = graph.copy()
  for e in answer.edges(data=True):
    e[2]['weight'] = weight_manipulation_function(e[2]['weight'])
  return answer

"""This function gets a graph and return maximum degree of that graph"""

def graph_max_degree(graph) -> int:
    degrees = []
    for node in graph:
        degrees.append(graph.degree(node))
    return max(degrees)

"""This method extracts all features from graph and put all of them as (key, value)"""

from networkx.algorithms.centrality.betweenness import betweenness_centrality
def graph_description(graph) -> dict:
  answer = {}
  reweighted_graph = reweight_graph(graph)
  answer["number_of_nodes"] = graph.number_of_nodes() # Number of nodes in graph
  answer["number_of_edges"] = graph.number_of_edges() # Number of edges in graph
  edges = []
  weights=[]
  for u,v,a in graph.edges(data=True):
    edges.append([u, v, a])
    weights.append(a["weight"])
  # answer["edges"] = edges # Edges of this graph
  # answer["weights_sum"] = sum(weights) # Summation of weights
  # answer["is_connected"] = nx.is_connected(graph) # Graph connectivity
  # answer["number_connected_components"] = nx.number_connected_components(graph) # Number of connected components in graph
  answer["connected_components"] = list(nx.connected_components(graph)) # List of connected components with their nodes
  answer["global_efficiency"] = nx.global_efficiency(graph) # Global efficiency of the graph
  answer["local_efficiency"] = nx.local_efficiency(graph) # Local efficiency of the graph
  answer["average_clustering"] = nx.average_clustering(graph) # Average clustering of the graph
  # answer["graph_clustering"] = nx.clustering(graph) # Clustering of the graph
  vertices_degrees = []
  nodes_results = {}
  for node in graph.__iter__():
    nodes_results[node] = {'degree': graph.degree(node)}
    vertices_degrees.append(graph.degree(node))
  communities_size = []
  for community in answer["connected_components"]:
    communities_size.append(len(community))
  communities_size.sort()
  vertices_degrees.sort()
  # answer["nodes_info"] = nodes_results # Information about all nodes
  # answer["degree_distribution_of_vertices"] = vertices_degrees # Sorted list of each vertex's degree
  # answer["communities_size"] = communities_size # List of each component size
  # answer["degree_centrality"] = nx.degree_centrality(graph) # Dictionary of nodes and their normalized degree
  # answer["average_degree_centrality"] = np.mean(list(answer['degree_centrality'].values())) # Average degree centrality
  # answer["betweenness_centrality"] = nx.betweenness_centrality(reweighted_graph, weight='weight') # Betweenness centrality of the graph
  # answer["average_betweenness_centrality"] = np.mean(list(answer['betweenness_centrality'].values())) # Average betweenness centrality
  # answer["closeness_centrality"] = nx.closeness_centrality(reweighted_graph, distance='weight') # Closeness centrality of the graph
  # answer["average_closeness_centrality"] = np.mean(list(answer['closeness_centrality'].values())) # Average closeness centrality
  # answer["small_worldness_omega"] = nx.omega(graph) # Omega coefficient of small worldness in the graph
  # answer["small_worldness_sigma"] = nx.sigma(graph) # Sigma coefficient of small worldness in the graph
  # answer["transitivity"] = nx.transitivity(graph) # Transitivity of the graph
  # answer["max_degree"] = graph_max_degree(graph) # Max degree of graph
  # try:
    # answer["average_shortest_path_length"] = nx.average_shortest_path_length(graph) # Average shortest path length of the graph
  # except:
    # answer["average_shortest_path_length"] = None
  # answer["tree_hierarchy"] = tree_hierarchy(graph) # Tree Hierarchy of the graph
  # if answer["is_connected"]:
    # answer["diameter"] = nx.diameter(graph) # Diameter of the graph if it's connected
  # else:
    # answer["diameter"] = float('inf') # Diameter of the graph if it's not connected
  return answer

"""This function return adjacency matrix for given graph"""

def get_adjacency_matrix(graph):
  return nx.adgacency_matrix(graph)

"""Compute number of leafs in given graph"""

def leaf_number(graph: nx.Graph)-> int:
  answer = 0
  for node in graph.nodes():
    if graph.degree(node) == 1:
      answer +=1 
  return answer

"""Compute $T_H = \frac{L}{2mBC_{max}}$ for given graph"""

def tree_hierarchy(graph: nx.Graph) -> float:
  leaf_num = leaf_number(graph)
  reweighted_graph = reweight_graph(graph)
  MST = nx.minimum_spanning_tree(reweighted_graph)
  m = len(MST.nodes()) - 1
  BC = nx.betweenness_centrality(MST)
  BC_max = BC[max(BC, key=BC.get)]
  if BC_max == 0 or m == 0:
    return float('inf')
  answer = leaf_num / (2 * m * BC_max)
  return answer

"""Return biggest connected component in given graph"""

def get_biggest_connected_component(graph: nx.Graph):
  S = [graph.subgraph(c).copy() for c in nx.connected_components(graph)]
  answer_len = 0
  answer = None
  for s in S:
    if len(s) > answer_len:
      answer = s
      answer_len = len(s)
  return answer

"""GraphAnalysis class which handle all operations from raw data to complicated graphs"""

class GraphAnalysis:
    def __init__(self, path: str) -> None: # Constructor
        self.users = [] # Users list
        self.questions = [] # Questions list
        self.comments = [] # Comments list
        self.get_data_from_database(path)

    def get_data_from_database(self, path: str) -> None:
        # This method connects to database with given path and load all users, questions and comments.
        sql_connection = sqlite3.connect(path)
        cursor = sql_connection.cursor()
        for row in cursor.execute('SELECT * FROM Users;'):
            u = User(row[0], row[1], row[2], row[3], row[4])
            self.users.append(u)
        for row in cursor.execute('SELECT * FROM Questions;'):
            q = Question(row[0], row[1], row[2], row[3], row[4], row[5])
            self.questions.append(q)
        for row in cursor.execute('SELECT * FROM Comments;'):
            c = Comment(row[0], row[1], row[2], row[3], row[4], row[5], row[6])
            self.comments.append(c)

    def get_user_by_UserID(self, UserID: str) -> User:
        # This method takes an UserID and returns it's User object
        for u in self.users:
            if u.UserID == UserID:
                return u
        return None

    def get_users_by_UserIDs(self, userIDs: list) -> list:
        # This method takes a list of UserIDs and returns list of User
        answer = []
        for id in userIDs:
          answer.append(self.get_user_by_UserID(id))
        return answer

    def get_questions_of_user(self, userID: str) -> list:
        # This method takes an user id and returns list of user's questions
        answer = []
        for question in self.questions:
            if question.QUserID == userID:
                answer.append(question)
        return answer

    def get_users_first_activity_date(self, userID: str) -> datetime:
        # This method takes an user id and returns date of user's first activity
        user_comments = self.get_comments_of_user(userID)
        user_questions = self.get_questions_of_user(userID)
        user_comments.sort(key=lambda x: x.CDate)
        user_questions.sort(key=lambda x: x.QDate)
        if not user_comments and not user_questions:
            return datetime(1389, 1, 1)
        elif not user_comments:
            if user_questions[0].QDate.year > 2000:
                return user_questions[1].QDate
            return user_questions[0].QDate
        elif not user_questions:
            return user_comments[0].CDate
        elif user_comments[0].CDate < user_questions[0].QDate:
            return user_comments[0].CDate
        else:
            return user_questions[0].QDate

    def get_users_last_activity_date(self, userID: str) -> datetime:
        # This method takes an user id and returns date of user's last activity
        user_comments = self.get_comments_of_user(userID)
        user_questions = self.get_questions_of_user(userID)
        user_comments.sort(key=lambda x: x.CDate, reverse=True)
        user_questions.sort(key=lambda x: x.QDate, reverse=True)
        if not user_comments and not user_questions:
            return datetime(1389, 1, 1)
        elif not user_comments:
            if user_questions[0].QDate.year > 2000:
                return user_questions[1].QDate
            return user_questions[0].QDate
        elif not user_questions:
            return user_comments[0].CDate
        elif user_comments[0].CDate > user_questions[0].QDate:
            return user_comments[0].CDate
        else:
            return user_questions[0].QDate


    def get_comments_of_user(self, UserID: str) -> list:
        # This method takes a UserID and return all comments of that specific user as list
        answer = []
        for comment in self.comments:
          if comment.CUserID == UserID:
            answer.append(comment)
        return answer

    def get_comments_by_QID(self, QID: str) -> list:
        # This method takes a QID(Questions ID) and returns all comments which belongs to the questions
        answer = []
        for c in self.comments:
            if c.QID == QID:
                answer.append(c)
        return answer

    def get_comment_by_CID(self, CID: str, space=None) -> Comment:
        # This method takes a CID(Comment ID) and optional space and return comment with that specific ID in that space.
        if not space:
            space = self.comments
        for c in space:
            if c.CID == CID:
                return c
        return None

    def get_commenters(self, comments_list: list) -> set:
        # This method takes a list of comments and return all users which wrote those commenters as a set.
        answer = set()
        for c in comments_list:
            answer.add(self.get_user_by_UserID(c.CUserID))
        return answer

    def get_question_by_QID(self, QID: str) -> Question:
        # This method takes a QID and returns its question
        answer = None
        for q in self.questions:
          if q.QID == QID:
            return q
        return answer

    def get_comments_min_year(self, comments=None) -> int:
        # This method returns minimum comments release date year
        answer = 2020
        if comments == None:
          comments = self.comments
        for comment in comments:
          if comment.CDate.year < answer:
            answer = comment.CDate.year
        return answer
    
    def get_comments_max_year(self, comments=None) -> int:
        # This method returns maximum comments release date year
        answer = 1000
        if comments == None:
          comments = self.comments
        for comment in self.comments:
          if comment.CDate.year > answer:
            answer = comment.CDate.year
        return answer

    def get_all_questions_graph(self) -> nx.Graph:
        # This method makes a directed graph and put all questions in this graph.
        # Each node will be a User and edges will be comments from commenter into the user who they replied to.
        graph = nx.Graph()
        graph.edges.data("weight", default=1)
        print("Number of questions:", len(self.questions))
        counter = 0
        for question in self.questions:
            counter += 1
            asker = self.get_user_by_UserID(question.QUserID)
            graph.add_node(asker)
            question_comments = self.get_comments_by_QID(question.QID)
            commenters = self.get_commenters(question_comments)
            if asker in commenters:
                commenters.remove(asker)
            if None in commenters:
                commenters.remove(None)
            graph.add_nodes_from(commenters)
            for c in question_comments:
                if not c.isReply:
                    try:
                        if not graph.has_edge(self.get_user_by_UserID(c.CUserID), asker):
                          graph.add_edge(self.get_user_by_UserID(c.CUserID), asker, weight=1)
                        else:
                          graph[self.get_user_by_UserID(c.CUserID)][asker]['weight'] += 1
                    except:
                        pass
                else:
                    try:
                        if not graph.has_edge(self.get_user_by_UserID(c.CUserID), self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID)):
                          graph.add_edge(self.get_user_by_UserID(c.CUserID),
                                       self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID), weight=1)
                        else:
                          graph[self.get_user_by_UserID(c.CUserID)][self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID)]['weight'] += 1
                    except:
                        pass
            if counter % 50 == 0:
                print('counter: ', counter)
        return graph

    def get_question_graph(self, question : Question) -> nx.Graph:
        # This method takes a question and return its directed graph.
        # Each node will be a User and comments will be edges.
        graph = nx.Graph()
        graph.edges.data("weight", default=1)
        asker = self.get_user_by_UserID(question.QUserID)
        graph.add_node(asker)
        question_comments = self.get_comments_by_QID(question.QID)
        commenters = self.get_commenters(question_comments)
        if asker in commenters:
            commenters.remove(asker)
        if None in commenters:
            commenters.remove(None)
        graph.add_nodes_from(commenters)
        for c in question_comments:
            if not c.isReply:
                try:
                  if not graph.has_edge(self.get_user_by_UserID(c.CUserID), asker):
                    graph.add_edge(self.get_user_by_UserID(c.CUserID), asker, weight=1)

                  else:
                    graph[self.get_user_by_UserID(c.CUserID)][asker]['weight'] += 1

                except:
                  pass
            else:
                try:
                    if not graph.has_edge(self.get_user_by_UserID(c.CUserID), self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID)):
                      graph.add_edge(self.get_user_by_UserID(c.CUserID),
                                   self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID), weight=1)
                    else:
                      graph[self.get_user_by_UserID(c.CUserID)][self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID)]['weight'] += 1
                except:
                    pass
        return graph

    def get_specific_questions_graph(self, questions_list: list) -> nx.Graph:
        # This method takes a list of questions and return directed graph of those questions.
        # Each node is an User and comments will be edges.
        graph = nx.Graph()
        graph.edges.data("weight", default=1)
        print("Number of questions: ", len(questions_list))
        counter = 0
        for question in questions_list:
            counter += 1
            asker = self.get_user_by_UserID(question.QUserID)
            graph.add_node(asker)
            question_comments = self.get_comments_by_QID(question.QID)
            commenters = self.get_commenters(question_comments)
            if asker in commenters:
                commenters.remove(asker)
            if None in commenters:
                commenters.remove(None)
            graph.add_nodes_from(commenters)
            for c in question_comments:
                if not c.isReply:
                    try:
                        if not graph.has_edge(self.get_user_by_UserID(c.CUserID), asker):
                          graph.add_edge(self.get_user_by_UserID(c.CUserID), asker, weight=1)
                        else:
                          graph[self.get_user_by_UserID(c.CUserID)][asker]['weight'] += 1
                    except:
                        pass
                else:
                    try:
                        if not graph.has_edge(self.get_user_by_UserID(c.CUserID), self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID)):
                          graph.add_edge(self.get_user_by_UserID(c.CUserID),
                                       self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID), weight=1)
                        else:
                          graph[self.get_user_by_UserID(c.CUserID)][self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID)]['weight'] += 1      
                    except:
                        pass
            if counter % 50 == 0:
                print('counter: ', counter)
        return graph

    def get_questions_by_year(self, year: int, condition='le') -> list:
        # This method takes year and condition and returns a list of questions which satisfy the condition for that year.
        # Condition could be le: lower equal, e: equal, he: higher equal, l: lower and h: higher
        answer = []
        for question in self.questions:
            if condition == 'le':
                if question.QDate.year <= year:
                    answer.append(question)
            elif condition == 'e':
                if question.QDate.year == year:
                    answer.append(question)
            elif condition == 'he':
                if question.QDate.year >= year:
                    answer.append(question)
            elif condition == 'l':
                if question.QDate.year < year:
                    answer.append(question)
            elif condition == 'h':
                if question.QDate.year > year:
                    answer.append(question)
        return answer

    def get_questions_by_interval(self, lower: int, upper: int, condition='closed') -> list:
        # This method takes two integers lower and upper for boundries and a condition and returns a list of questions which in that interval
        # Condition could be closed or open.
        answer = []
        for question in self.questions:
            if condition == 'closed':
                if upper >= question.QDate.year >= lower:
                    answer.append(question)
            elif condition == 'open':
                if upper > question.QDate.year > lower:
                    answer.append(question)
            else:
                assert "Bad condition"
        return answer

    def min_question_year(self) -> int:
        # This method returns minimum year of questions.
        answer = 2030
        for question in self.questions:
            if question.QDate.year < answer:
                answer = question.QDate.year
        return answer

    def max_question_year(self) -> int:
        # This method returns maximum year of questions.
        answer = 0
        for question in self.questions:
            if question.QDate.year > answer:
                answer = question.QDate.year
        return answer

    def get_questions_years_describe(self) -> dict:
        # This method returns a dictionary which describe questions frequency by the year they deployed.
        answer = {}
        min_year = self.min_question_year()
        max_year = self.max_question_year()
        for i in range(min_year, max_year + 1):
            answer[i] = 0
        for question in self.questions:
            answer[question.QDate.year] += 1
        return answer

    def get_question_visit_in_each_year(self) -> dict:
        # This method returns a dictionary which indicates how many people visited questions in that year
        answer = {}
        min_year = self.min_question_year()
        max_year = self.max_question_year()
        for year in range(min_year, max_year + 1):
            counter = 0
            for question in self.get_questions_by_year(year, 'e'):
              counter += question.QVisit
            answer[year] = counter
        return answer

    def split_comments_by_year(self) -> dict:
        # This method returns a dictionary contains each year's comments in an array
        min_year = self.get_comments_min_year()
        max_year = self.get_comments_max_year()
        answer = {}
        for year in range(min_year, max_year + 1):
            comms = self.get_comments_by_year(year, 'e')
            answer[year] = comms
        return answer

    def split_questions_by_year(self) -> dict:
        # This method returns a dictionary contains each year's questions in an array
        min_year = self.min_question_year()
        max_year = self.max_question_year()
        answer = {}
        for year in range(min_year, max_year + 1):
            questions = self.get_questions_by_year(year, 'e')
            answer[year] = questions
        return answer

    def plot_question_user_base(self, question: Question) -> None:
        # This method takes a question and plot a directed graph for it.
        graph = nx.Graph(question=question)
        graph.edges.data("weight", default=1)
        asker = self.get_user_by_UserID(question.QUserID)
        print("Asker: ", asker)
        graph.add_node(asker)
        color_map = ['red']
        question_comments = self.get_comments_by_QID(question.QID)
        commenters = self.get_commenters(question_comments)
        if asker in commenters:
            commenters.remove(asker)
        if None in commenters:
            commenters.remove(None)
        print("Number of commenters:", len(commenters))
        for _ in range(len(commenters)):
            color_map.append('green')
        graph.add_nodes_from(commenters)
        for c in question_comments:
            if not c.isReply:
                try:
                    if not graph.has_edge(self.get_user_by_UserID(c.CUserID), asker):
                      graph.add_edge(self.get_user_by_UserID(c.CUserID), asker, weight=1)
                    else:
                      graph[self.get_user_by_UserID(c.CUserID)][asker]['weight'] += 1
                except:
                    pass
            else:
                try:
                    if not graph.has_edge(self.get_user_by_UserID(c.CUserID), self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID)):
                      graph.add_edge(self.get_user_by_UserID(c.CUserID),
                                    self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID), weight=1)
                    else:
                      graph[self.get_user_by_UserID(c.CUserID)][self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID)]['weight'] += 1      
                except:
                    pass
        nx.draw(graph, with_labels=False, node_color=color_map, node_size=60)
        print("Number of nodes: ", graph.number_of_nodes())
        plt.show()

    def plot_all_questions(self) -> None:
        # This method plots a directed graph which contains all questions' graph
        plot_graph(self.get_all_questions_graph(), 20)

    def plot_questions(self, questions: list) -> None:
      # This method plots a list of questions
      for question in questions:
        self.plot_question_user_base(question)

    def get_comments_of_question_by_time(self, question: Question, year: int, condition='e') -> list:
      # This method returns comments of given question in a specific year.
      # Condition should be e, le, l, he, h (e=equal, h=higher, l=lower)
      answer = []
      question_comments = self.get_comments_by_QID(question.QID)
      for comment in question_comments:
        if condition == 'e':
          if comment.CDate.year == year:
            answer.append(comment)
        elif condition == 'le':
          if comment.CDate.year <= year:
            answer.append(comment)
        elif condition == 'l':
          if comment.CDate.year < year:
            answer.append(comment)
        elif condition == 'he':
          if comment.CDate.year >= year:
            answer.append(comment)
        elif condition == 'h':
          if comment.CDate.year > year:
            answer.append(comment)
        else:
          assert "Invalid condition"
      return answer
    def get_question_description(self, question: Question) -> dict:
      # This method returns a description about question in dictionary format
      description = {}
      question_comments = self.get_comments_by_QID(question.QID)
      # Number of comments
      description['comments_number'] = len(question_comments)
      if len(question_comments) != 0:
        # Min and Max year for comments
        min_year = 2100
        max_year = 100
        for comment in question_comments:
          if comment.CDate.year > max_year:
            max_year = comment.CDate.year
          if comment.CDate.year < min_year:
            min_year = comment.CDate.year
        description['max_year'] = max_year
        description['min_year'] = min_year

        # Comments distribution over years
        years = [0 for i in range(min_year, max_year + 1)]
        for i in range(min_year, max_year + 1):
          counter = 0
          for comment in question_comments:
            if comment.CDate.year == i:
              counter += 1
          years[i - min_year] = counter
        description["year_distribution"] = years

      return description

    def plot_question_over_time(self, question: Question):
      # This method get's a question and plots it's comments over years.
      # It starts from beginning to the end.
      graph = nx.Graph()
      graph.edges.data("weight", default=1)
      asker = self.get_user_by_UserID(question.QUserID)
      graph.add_node(asker)
      question_description = self.get_question_description(question)
      print(question_description)
      if question_description['comments_number'] == 0:
          assert "Bad Question"
      min_year = question_description['min_year']
      max_year = question_description['max_year']
      figure_counter = 2
      plt.figure(1, figsize=(12, 12))
      nx.draw(graph, with_labels=False, node_size=60)
      plt.show()
      for i in range(min_year, max_year + 1):
        comments_itr = self.get_comments_of_question_by_time(question, i, 'le')
        if comments_itr == None:
          continue  
        print("year: " + str(i))     
        commenters = self.get_commenters(comments_itr)
        if asker in commenters:
          commenters.remove(asker)
        if None in commenters:
          commenters.remove(None)
        for _ in range(len(commenters)):
          graph.add_nodes_from(commenters)
        print("Graph's node counter: " + str(graph.number_of_nodes()))
        for c in comments_itr:
          if not c.isReply:
            try:
                if not graph.has_edge(self.get_user_by_UserID(c.CUserID), asker):
                  graph.add_edge(self.get_user_by_UserID(c.CUserID), asker, weight=1)
                else:
                  graph[self.get_user_by_UserID(c.CUserID)][asker]['weight'] += 1
            except:
                  pass
          else:
              try:
                  if not graph.has_edge(self.get_user_by_UserID(c.CUserID), self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID)):
                    graph.add_edge(self.get_user_by_UserID(c.CUserID),
                                    self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID), weight=1)
                  else:
                    graph[self.get_user_by_UserID(c.CUserID)][self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID)]['weight'] += 1
              except:
                  pass
        plt.figure(figure_counter, figsize=(12, 12))
        nx.draw(graph, with_labels=False, node_size=60)
        plt.show()
      commenters = self.get_commenters(self.get_comments_by_QID(question.QID))
      s = 0
      for c in commenters:
        print(graph.get_edge_data(asker, c))
        s += graph.get_edge_data(asker, c)['weight']
      print(s)

    def get_comments_by_year(self, year: int, condition='e', comments=None):
      answer = []
      if not comments:
        comments = self.comments
      for comment in comments:
        if condition == 'le':
          if comment.CDate.year <= year:
            answer.append(comment)
        elif condition == 'e':
          if comment.CDate.year == year:
            answer.append(comment)
        elif condition == 'he':
          if comment.CDate.year >= year:
            answer.append(comment)
        elif condition == 'h':
          if comment.CDate.year > year:
            answer.append(comment)
        elif condition == 'l':
          if comment.CDate.year < year:
            answer.append(comment)
        else:
          assert "Invalid Condition"
      return answer


    def get_year_to_year_graph(self) -> dict:
      answer = {}
      comments = self.comments
      users_ids = set()
      for comment in comments:
        users_ids.add(comment.CUserID)
        users_ids.add(self.get_question_by_QID(comment.QID).QUserID)
      users = self.get_users_by_UserIDs(list(users_ids))
      min_year = self.get_comments_min_year()
      max_year = self.get_comments_max_year()
      graph = nx.Graph()
      graph.edges.data('weight', default=1)
      for year in range(min_year, max_year + 1):
          comments = self.get_comments_by_year(year, 'e')
          print("Year: ", year)
          for c in comments:
            question = self.get_question_by_QID(c.QID)
            asker = self.get_user_by_UserID(question.QUserID)
            if not c.isReply:
              try:
                if not graph.has_edge(self.get_user_by_UserID(c.CUserID), asker):
                  graph.add_edge(self.get_user_by_UserID(c.CUserID), asker, weight=1)
                else:
                  graph[self.get_user_by_UserID(c.CUserID)][asker]['weight'] += 1
              except:
                pass
            else:
              try:
                  if not graph.has_edge(self.get_user_by_UserID(c.CUserID), self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID)):
                    graph.add_edge(self.get_user_by_UserID(c.CUserID),
                                  self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID), weight=1)
                  else:
                    graph[self.get_user_by_UserID(c.CUserID)][self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID)]['weight'] += 1      
              except:
                  pass
          answer[year] = graph.copy()
          print(graph.number_of_nodes())
          print(graph.number_of_edges())
      return answer

    '''
    Problem: When we started to create graphs with simple approach, at the end we have an axillary node.
    Solution: The problem was due to some technical issues, networkx can not compare users with each other and due to this, if we use add_nodes_from method
    # networkx will consider all array elements as an unique node so this will lead us to one axillary node. 
    '''

    def get_BCC_year_per_year(self) -> dict:
        # This method returns Biggest Connected Component graph for each year
        all_questions_graph = self.get_all_questions_graph()
        BCC_graph = get_biggest_connected_component(all_questions_graph)
        print("Number of BCC_graph nodes:", len(BCC_graph.nodes))
        print("Number of BCC_graph edges:", len(BCC_graph.edges))
        graph = nx.Graph()
        graph.add_nodes_from(BCC_graph)
        user_ids = set()
        for node in graph.nodes:
            user_ids.add(node.UserID)
        print("Number of graph nodes:", len(graph.nodes))
        users = self.get_users_by_UserIDs(user_ids)
        comments = []
        for user in users:
            comments += self.get_comments_of_user(user.UserID)
        print("length of comments:", len(comments))
        min_year = 2020
        max_year = 1000
        for comment in comments:
            if comment.CDate.year < min_year:
              min_year = comment.CDate.year
            if comment.CDate.year > max_year:
              max_year = comment.CDate.year
        print(min_year, max_year)
        annual_comments = {}
        for year in range(min_year, max_year + 1):
            year_comments = []
            for comment in comments:
                if comment.CDate.year == year:
                    year_comments.append(comment)
            annual_comments[year] = year_comments
            print("year:", year)
            print("comments length:", len(year_comments))

        graph = nx.Graph()
        graph.edges.data('weight', default=1)
        annual_graph = {}
        for year in annual_comments.keys():
            comms = annual_comments[year]
            print("Year:", year)
            for c in comms:
                question = self.get_question_by_QID(c.QID)
                asker = self.get_user_by_UserID(question.QUserID)
                if not c.isReply:
                  try:
                    if not graph.has_edge(self.get_user_by_UserID(c.CUserID), asker):
                      graph.add_edge(self.get_user_by_UserID(c.CUserID), asker, weight=1)
                    else:
                      graph[self.get_user_by_UserID(c.CUserID)][asker]['weight'] += 1
                  except:
                    pass
                else:
                  try:
                      if not graph.has_edge(self.get_user_by_UserID(c.CUserID), self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID)):
                        graph.add_edge(self.get_user_by_UserID(c.CUserID),
                                      self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID), weight=1)
                      else:
                        graph[self.get_user_by_UserID(c.CUserID)][self.get_user_by_UserID(self.get_comment_by_CID(c.ParentID).CUserID)]['weight'] += 1      
                  except:
                      pass
            annual_graph[year] = graph.copy()
            print("number of nodes:", len(graph.nodes))
            print("number of edges:", len(graph.edges))
        return annual_graph

    def get_questions_data_frame(self) -> pd.DataFrame:
        # This method returns a dataframe of each question with four main columns. Days, Duration, Comments number and Visits
        questions = self.questions
        start_time = datetime(1389,1,1)
        days = []
        durations = []
        comment_nums = []
        post_views = []
        for question in questions:
            if question.QDate.year > 2000:
                continue
            QDate = question.QDate
            day_diff = dateTime_to_int(QDate, start_time)
            days.append(day_diff)
            comments = self.get_comments_by_QID(question.QID)
            comments.sort(key=lambda x: x.CDate)
            post_views.append(question.QVisit)
            if len(comments) == 0:
                durations.append(0)
                comment_nums.append(0)
            else:
                durations.append(dateTime_to_int(comments[-1].CDate, question.QDate))
                comment_nums.append(len(comments))
        
        d = {'Days': days, 'Duration': durations, 'Comments number': comment_nums, 'Question Visit': post_views}
        answer  = pd.DataFrame(data=d)
        return answer

    def get_users_data_frame(self) -> pd.DataFrame:
        # This method returns a dataframe of each user with three main columns. First Activity, Lost - First Activity and Post Count
        users = self.users
        start_time = datetime(1389, 1, 1)
        first_activity_dates = []
        diff_activity_dates = []
        comment_nums = []
        for user in users:
            first_act = self.get_users_first_activity_date(user.UserID)
            last_act = self.get_users_last_activity_date(user.UserID)
            first_activity_dates.append(dateTime_to_int(first_act, start_time))
            diff_activity_dates.append(dateTime_to_int(last_act, first_act))
            comment_nums.append(user.PostCount)
        d = {'First Activity(Day)': first_activity_dates, 'Last - First activity(Day)': diff_activity_dates, 'Post counts': comment_nums}
        answer = pd.DataFrame(data=d)
        return answer

"""### Description of all records graph for group1:"""

graphAnalysis = GraphAnalysis("/content/drive/MyDrive/Data_Bases/Group1_Results/PurifiedGroup1/Group1_2_2.db")

"""#### All questions graph analysis"""

all_graph = graphAnalysis.get_all_questions_graph()

"""Diameter of all_graph is infinite"""

plot_graph(all_graph)

description = graph_description(all_graph)

import pickle
f = open("all_graph_group1_centralities.pkl", "wb")
pickle.dump(description, f)
f.close()

import pickle
f = open("all_graph_group1.pkl", "wb")
pickle.dump(description, f)
f.close()

description['number_of_nodes']

description['number_of_edges']

description['edges']

description['weights_sum']

description['is_connected']

description['number_connected_components']

description['connected_components']

description['global_efficiency']

description['local_efficiency']

description['graph_clustering']

description['nodes_info']

description['degree_distribution_of_vertices']

description['communities_size']

description['degree_centrality']

description['betweenness_centrality']

description['closeness_centrality']

description['diameter']

plot_degree_histogram(description)

plot_communities_size_histogram(description)

plot_degree_distribution(description)

plot_communities_distribution(description)

description["average_clustering"]

description["transitivity"]

description["small_worldness_sigma"]

description["small_worldness_omega"]

print(nx.constraint(all_graph))

print(nx.effective_size(all_graph))

"""####Year to year graph for group 1"""

year_to_year_graph = graphAnalysis.get_year_to_year_graph()

"""Plot of each year graph"""

for year in year_to_year_graph.keys():
  print("Year: ", year)
  plot_graph(year_to_year_graph[year])

"""Year to year graph descriptions"""

year_to_year_description = {}
for year in year_to_year_graph.keys():
  print("Year:", year)
  year_to_year_description[year] = graph_description(year_to_year_graph[year])

"""Print description of each year graph sperately """

for year in year_to_year_description.keys():
  print('-'*60)
  print("Description of year", year, ':')
  description = year_to_year_description[year]
  for feature in features_names:
    print(feature, ': ', description[feature])

for year in year_to_year_description.keys():
  print("Year:", year)
  plot_distribution(year_to_year_description[year]['degree_distribution_of_vertices'])

"""Number of nodes in each year"""

plot_features_year_to_year(year_to_year_description, "number_of_nodes")

"""Curve fitted for number of nodes"""

plot_features_year_to_year_scatter(year_to_year_description, 'number_of_nodes')

"""Number of edges in each year"""

plot_features_year_to_year(year_to_year_description, "number_of_edges")

"""Curve fitted for number of edges"""

plot_features_year_to_year_scatter(year_to_year_description, 'number_of_edges')

"""Weights sum in each year"""

plot_features_year_to_year(year_to_year_description, "weights_sum")

"""Curve fitting in weights sum"""

plot_features_year_to_year_scatter(year_to_year_description, 'weights_sum')

"""Number of connected components in each year"""

plot_features_year_to_year(year_to_year_description, "number_connected_components")

plot_features_year_to_year_scatter(year_to_year_description, "number_connected_components")

"""Global efficiency in each year"""

plot_features_year_to_year(year_to_year_description, "global_efficiency")

"""Local efficiency in each year"""

plot_features_year_to_year(year_to_year_description, "local_efficiency")

"""Tree hierarchy in each year"""

plot_features_year_to_year(year_to_year_description, "tree_hierarchy")

plot_features_year_to_year(year_to_year_description, "average_clustering")

plot_features_year_to_year(year_to_year_description, "transitivity")

plot_features_year_to_year(year_to_year_description, "max_degree")

plot_features_year_to_year(year_to_year_description, "average_degree_centrality")

plot_features_year_to_year(year_to_year_description, "average_betweenness_centrality")

plot_features_year_to_year(year_to_year_description, "average_closeness_centrality")

for year in year_to_year_description.keys():
  print("Year: ", year)
  print("Constraints: ", nx.constraint(year_to_year_description[year]))

for year in year_to_year_description.keys():
  print("Year: ", year)
  print("Effective Size: ", nx.effective_size(year_to_year_description[year]))

"""####Biggest Connected Component in group 1 description:"""

BCC_group1 = get_biggest_connected_component(all_graph)

len(BCC_group1)

BCC_group1_description = graph_description(BCC_group1)

f = open("BCC_group1_centralities.pkl", "wb")
pickle.dump(BCC_group1_description, f)
f.close()

f = open("BCC_group1.pkl", "wb")
pickle.dump(BCC_group1_description, f)
f.close()

BCC_group1_description['number_of_nodes']

BCC_group1_description['number_of_edges']

BCC_group1_description['edges']

BCC_group1_description['weights_sum']

BCC_group1_description['is_connected']

BCC_group1_description['number_connected_components']

BCC_group1_description['global_efficiency']

BCC_group1_description['local_efficiency']

BCC_group1_description['graph_clustering']

BCC_group1_description['nodes_info']

BCC_group1_description['degree_distribution_of_vertices']

BCC_group1_description['communities_size']

BCC_group1_description['degree_centrality']

BCC_group1_description['betweenness_centrality']

BCC_group1_description['closeness_centrality']

BCC_group1_description['average_shortest_path_length']

BCC_group1_description['tree_hierarchy']

BCC_group1_description['diameter']

BCC_group1_description['average_clustering']

BCC_group1_description['transitivity']

BCC_group1_description['small_worldness_sigma']

BCC_group1_description['small_worldness_omega']

print(nx.contraint(BCC_group1))

print(nx.effective_size(BCC_group1))

"""####Biggest Connected Component year to year

Getting BCC of group 1 year per year
"""

YTY_BCC = graphAnalysis.get_BCC_year_per_year()

"""Plot graph each year"""

for year in YTY_BCC.keys():
    print("Year:", year)
    plot_graph(YTY_BCC[year])

"""Get year to year description"""

YTY_description = {}
for year in YTY_BCC.keys():
    des = graph_description(YTY_BCC[year])
    YTY_description[year] = des

"""Plot degree distribution of vertices"""

for year in YTY_description.keys():
  print("Year:", year)
  plot_distribution(YTY_description[year]['degree_distribution_of_vertices'])

"""Number of nodes in each year"""

plot_features_year_to_year(YTY_description, "number_of_nodes")

"""Curve fitting for number of nodes"""

plot_features_year_to_year_scatter(YTY_description, 'number_of_nodes')

"""Number of edges in each year"""

plot_features_year_to_year(YTY_description, "number_of_edges")

"""Curve fitting of number of edges"""

plot_features_year_to_year_scatter(YTY_description, 'number_of_edges')

"""Weights summation in each year"""

plot_features_year_to_year(YTY_description, "weights_sum")

"""Curve fitting on weights sum"""

plot_features_year_to_year_scatter(YTY_description, 'weights_sum')

"""Number of connected components in each year"""

plot_features_year_to_year(YTY_description, "number_connected_components")

plot_features_year_to_year_scatter(YTY_description, "number_connected_components")

"""Global efficiency in each year"""

plot_features_year_to_year(YTY_description, "global_efficiency")

"""Local efficiency in each year"""

plot_features_year_to_year(YTY_description, "local_efficiency")

"""Tree hierarchy in each year"""

plot_features_year_to_year(YTY_description, "tree_hierarchy")

"""Average Clustering plot"""

plot_features_year_to_year(YTY_description, "average_clustering")

"""Transitivity plot"""

plot_features_year_to_year(YTY_description, "transitivity")

plot_features_year_to_year(YTY_description, "max_degree")

plot_features_year_to_year(YTY_description, "average_degree_centrality")

plot_features_year_to_year(YTY_description, "average_betweenness_centrality")

plot_features_year_to_year(YTY_description, "average_closeness_centrality")

"""#### 4D plots for group 1

Questions
"""

plot_4D_Questions(graphAnalysis.get_questions_data_frame())

"""Users"""

plot_4D_Users(graphAnalysis.get_users_data_frame())

"""### Description of all records graph for group 2 :"""

graphAnalysis2 = GraphAnalysis("/content/drive/MyDrive/Data_Bases/Group2_Results/Group2_2.db")

"""#### All questions graph analysis"""

all_graph_group2 = graphAnalysis2.get_all_questions_graph()

plot_graph(all_graph_group2)

description2 = graph_description(all_graph_group2)

import pickle
f = open("all_graph_group2_centralities.pkl", "wb")
pickle.dump(description2, f)
f.close()

f = open("all_graph_group2.pkl", "wb")
pickle.dump(description2, f)
f.close()

description2['number_of_nodes']

description2['number_of_edges']

description2['edges']

description2['weights_sum']

description2['is_connected']

description2['number_connected_components']

description2['connected_components']

description2['global_efficiency']

description2['local_efficiency']

description2['graph_clustering']

description2['nodes_info']

description2['degree_distribution_of_vertices']

description2['communities_size']

description2['degree_centrality']

description2['betweenness_centrality']

description2['closeness_centrality']

description2['diameter']

description2['average_clustering']

description2['transitivity']

description2['small_worldness_omega']

description2['small_worldness_sigma']

plot_degree_histogram(description2)

plot_communities_size_histogram(description2)

plot_degree_distribution(description2)

plot_communities_distribution(description2)

"""####Year to year description

Getting each year graph
"""

year_to_year_graph2 = graphAnalysis2.get_year_to_year_graph()

"""Plot each year graph"""

for year in year_to_year_graph2.keys():
  print("Year: ", year)
  plot_graph(year_to_year_graph2[year])

"""Get each year graph's description"""

year_to_year_description2 = {}
for year in year_to_year_graph2.keys():
  print("Year: ", year)
  year_to_year_description2[year] = graph_description(year_to_year_graph2[year])

"""Print each year's description"""

for year in year_to_year_description2.keys():
  print('-'*60)
  print("Description of year", year, ':')
  description = year_to_year_description2[year]
  for feature in features_names:
    print(feature, ': ', description[feature])

"""Plot degree distribution of vertices"""

for year in year_to_year_description2.keys():
  print("Year:", year)
  plot_distribution(year_to_year_description2[year]['degree_distribution_of_vertices'])

"""Number of nodes in each year"""

plot_features_year_to_year(year_to_year_description2, "number_of_nodes")

"""Curve fitting for number of nodes"""

plot_features_year_to_year_scatter(year_to_year_description2, 'number_of_nodes')

"""Number of edges in each year"""

plot_features_year_to_year(year_to_year_description2, "number_of_edges")

"""Curve fitting of number of edges"""

plot_features_year_to_year_scatter(year_to_year_description2, 'number_of_edges')

"""Weights summation in each year"""

plot_features_year_to_year(year_to_year_description2, "weights_sum")

"""Curve fitting on weights sum"""

plot_features_year_to_year_scatter(year_to_year_description2, 'weights_sum')

"""Number of connected components in each year"""

plot_features_year_to_year(year_to_year_description2, "number_connected_components")

plot_features_year_to_year_scatter(year_to_year_description2, "number_connected_components")

"""Global efficiency in each year"""

plot_features_year_to_year(year_to_year_description2, "global_efficiency")

"""Local efficiency in each year"""

plot_features_year_to_year(year_to_year_description2, "local_efficiency")

"""Tree hierarchy in each year"""

plot_features_year_to_year(year_to_year_description2, "tree_hierarchy")

plot_features_year_to_year(year_to_year_description2, "average_clustering")

plot_features_year_to_year(year_to_year_description2, "transitivity")

plot_features_year_to_year(year_to_year_description2, "max_degree")

plot_features_year_to_year(year_to_year_description2, "average_degree_centrality")

plot_features_year_to_year(year_to_year_description2, "average_betweenness_centrality")

plot_features_year_to_year(year_to_year_description2, "average_closeness_centrality")

"""####Biggest Connected Component Description for Group 2:"""

BCC_group2 = get_biggest_connected_component(all_graph_group2)

BCC_group2_description = graph_description(BCC_group2)

f = open("BCC_group2_centralities.pkl", "wb")
pickle.dump(BCC_group2_description, f)
f.close()

f = open("BCC_group2.pkl", "wb")
pickle.dump(BCC_group2_description, f)
f.close()

BCC_group2_description['number_of_nodes']

BCC_group2_description['number_of_edges']

BCC_group2_description['edges']

BCC_group2_description['weights_sum']

BCC_group2_description['is_connected']

BCC_group2_description['number_connected_components']

BCC_group2_description['global_efficiency']

BCC_group2_description['local_efficiency']

BCC_group2_description['graph_clustering']

BCC_group2_description['nodes_info']

BCC_group2_description['degree_distribution_of_vertices']

BCC_group2_description['communities_size']

BCC_group2_description['degree_centrality']

BCC_group2_description['betweenness_centrality']

BCC_group2_description['closeness_centrality']

BCC_group2_description['average_shortest_path_length']

BCC_group2_description['tree_hierarchy']

BCC_group2_description['diameter']

BCC_group2_description['average_clustering']

BCC_group2_description['transitivity']

BCC_group2_description['small_worldness_omega']

BCC_group2_description['small_worldness_sigma']

"""####Biggest Connected Component year to year

Getting BCC of group 2 year per year
"""

YTY_BCC2 = graphAnalysis2.get_BCC_year_per_year()

"""Plot graph each year"""

for year in YTY_BCC2.keys():
    print("Year:", year)
    plot_graph(YTY_BCC2[year])

"""Get year to year description"""

YTY_description2 = {}
for year in YTY_BCC2.keys():
    des = graph_description(YTY_BCC2[year])
    YTY_description2[year] = des

"""Plot degree distribution of vertices"""

for year in YTY_description2.keys():
  print("Year:", year)
  plot_distribution(YTY_description2[year]['degree_distribution_of_vertices'])

"""Number of nodes in each year"""

plot_features_year_to_year(YTY_description2, "number_of_nodes")

"""Curve fitting for number of nodes"""

plot_features_year_to_year_scatter(YTY_description2, 'number_of_nodes')

"""Number of edges in each year"""

plot_features_year_to_year(YTY_description2, "number_of_edges")

"""Curve fitting of number of edges"""

plot_features_year_to_year_scatter(YTY_description2, 'number_of_edges')

"""Weights summation in each year"""

plot_features_year_to_year(YTY_description2, "weights_sum")

"""Curve fitting on weights sum"""

plot_features_year_to_year_scatter(YTY_description2, 'weights_sum')

"""Number of connected components in each year"""

plot_features_year_to_year(YTY_description2, "number_connected_components")

plot_features_year_to_year_scatter(YTY_description2, "number_connected_components")

"""Global efficiency in each year"""

plot_features_year_to_year(YTY_description2, "global_efficiency")

"""Local efficiency in each year"""

plot_features_year_to_year(YTY_description2, "local_efficiency")

"""Tree hierarchy in each year"""

plot_features_year_to_year(YTY_description2, "tree_hierarchy")

"""Average Clustering plot"""

plot_features_year_to_year(YTY_description2, "average_clustering")

"""Transitivity plot"""

plot_features_year_to_year(YTY_description2, "transitivity")

plot_features_year_to_year(YTY_description2, "max_degree")

plot_features_year_to_year(YTY_description2, "average_degree_centrality")

plot_features_year_to_year(YTY_description2, "average_betweenness_centrality")

plot_features_year_to_year(YTY_description2, "average_closeness_centrality")

"""#### 4D plots for group 1

Questions
"""

plot_4D_Questions(graphAnalysis2.get_questions_data_frame())

"""Users"""

plot_4D_Users(graphAnalysis2.get_users_data_frame())

"""### Tree Hierarchy for questions :

This function creates information dictionary for given list of questions
"""

def get_tree_hierarchy_for_questions(questions: list) -> dict:
  answer = {}
  counter = 0
  for question in questions:
    counter += 1
    try:
      graph = graphAnalysis.get_question_graph(question)
      leaf_num = leaf_number(graph)
      TH = tree_hierarchy(graph)
      answer[question] = (leaf_num, TH)
    except:
      pass
    if counter % 50 == 0:
      print("counter: ", counter)
  return answer

"""#### Information about group 1:"""

questions = graphAnalysis.questions
information = get_tree_hierarchy_for_questions(questions)
information

plot_tree_hierarchy(information)

plot_leaf_numbers(information)

"""#### For Group 2 :"""

questions2 = graphAnalysis2.questions
information2 = get_tree_hierarchy_for_questions(questions2)
information2

plot_tree_hierarchy(information2)

plot_leaf_numbers(information2)

"""### Compare two groups:

Compare number of nodes
"""

plot_features_year_to_year_scatter_comparison(year_to_year_description, year_to_year_description2, 'number_of_nodes')

"""Compare number of edges"""

plot_features_year_to_year_scatter_comparison(year_to_year_description, year_to_year_description2, 'number_of_edges')

"""Compare weights sum"""

plot_features_year_to_year_scatter_comparison(year_to_year_description, year_to_year_description2, 'weights_sum')

"""### Test :

"""

test = GraphAnalysis("/content/drive/MyDrive/Data_Bases/Group2_Results/Group2_2.db")

questions_dataframe = test.get_questions_data_frame()

questions_dataframe

np.min(questions_dataframe['Comments number'])

np.max(questions_dataframe['Comments number'])

np.min(questions_dataframe['Question Visit'])

np.max(questions_dataframe['Question Visit'])

hue_colors = {
    'x < 1000' : '#9999ff',
    '1000 <= x < 2000' : '#8080ff',
    '2000 <= x < 3000' : '#6666ff',
    '3000 <= x < 4000' : '#4d4dff',
    '4000 <= x < 5000' : '#3333ff',
    '5000 <= x < 10000' : '#1a1aff',
    '10000 <= x < 15000' : '#0000ff',
    '15000 <= x' : '#0000e6'
}

def plot_test(data_frame: pd.DataFrame) -> None:
    sns.set_theme(style="white")
    cmap = sns.color_palette("ch:s=.25,rot=-.25", as_cmap=True)
    rel_plot = sns.relplot(x="Days", y="Duration", size="Comments number", hue="Question Visit Group",
                sizes=(20, 400), alpha=.8, palette=hue_colors,
                height=10, data=data_frame, 
                hue_order=['x < 1000', '1000 <= x < 2000', '2000 <= x < 3000', '3000 <= x < 4000', '4000 <= x < 5000', '5000 <= x < 10000', '10000 <= x < 15000', '15000 <= x'])
    plt.grid()
    plt.show()

plot_test(questions_dataframe)

question_visits = [visit for visit in questions_dataframe['Question Visit']]

plt.hist(question_visits)

q1 = []
q2 = []
q3 = []
q4 = []
for visit in question_visits:
    if visit < 5000:
        q1.append(visit)
    if 5000 <= visit < 10000:
        q2.append(visit)
    if 10000 <= visit < 15000:
        q3.append(visit)
    if 15000 <= visit:
        q4.append(visit)

plt.hist(q1)

plt.hist(q2)

plt.hist(q3)

plt.hist(q4)

questions = test.questions
start_time = datetime(1389,1,1)
days = []
durations = []
comment_nums = []
post_views = []
post_groups = []
for question in questions:
    if question.QDate.year > 2000:
        continue
    QDate = question.QDate
    day_diff = dateTime_to_int(QDate, start_time)
    days.append(day_diff)
    comments = test.get_comments_by_QID(question.QID)
    comments.sort(key=lambda x: x.CDate)
    post_views.append(question.QVisit)
    if question.QVisit < 1000:
        post_groups.append('x < 1000')
    elif question.QVisit < 2000:
        post_groups.append('1000 <= x < 2000')
    elif question.QVisit < 3000:
        post_groups.append('2000 <= x < 3000')
    elif question.QVisit < 4000:
        post_groups.append("3000 <= x < 4000")
    elif question.QVisit < 5000:
        post_groups.append("4000 <= x < 5000")
    elif question.QVisit < 10000:
        post_groups.append("5000 <= x < 10000")
    elif question.QVisit < 15000:
        post_groups.append("10000 <= x < 15000")
    else:
        post_groups.append("15000 <= x")
    if len(comments) == 0:
        durations.append(0)
        comment_nums.append(0)
    else:
        durations.append(dateTime_to_int(comments[-1].CDate, question.QDate))
        comment_nums.append(len(comments))

d = {'Days': days, 'Duration': durations, 'Comments number': comment_nums, 'Question Visit': post_views, "Question Visit Group": post_groups}
answer  = pd.DataFrame(data=d)

plot_test(answer)

test2 = GraphAnalysis("/content/drive/MyDrive/Data_Bases/Group1_Results/PurifiedGroup1/Group1_2_2.db")

questions_dataframe2 = test2.get_questions_data_frame()

question_visits = [visit for visit in questions_dataframe2['Question Visit']]

plt.hist(question_visits)

q1 = []
q2 = []
q3 = []
q4 = []
for visit in question_visits:
    if visit < 5000:
        q1.append(visit)
    if 5000 <= visit < 10000:
        q2.append(visit)
    if 10000 <= visit < 15000:
        q3.append(visit)
    if 15000 <= visit:
        q4.append(visit)

plt.hist(q1)

plt.hist(q2)

plt.hist(q3)

plt.hist(q4)

questions = test2.questions
start_time = datetime(1389,1,1)
days = []
durations = []
comment_nums = []
post_views = []
post_groups = []
for question in questions:
    if question.QDate.year > 2000:
        continue
    QDate = question.QDate
    day_diff = dateTime_to_int(QDate, start_time)
    days.append(day_diff)
    comments = test2.get_comments_by_QID(question.QID)
    comments.sort(key=lambda x: x.CDate)
    post_views.append(question.QVisit)
    if question.QVisit < 1000:
        post_groups.append('x < 1000')
    elif question.QVisit < 2000:
        post_groups.append('1000 <= x < 2000')
    elif question.QVisit < 3000:
        post_groups.append('2000 <= x < 3000')
    elif question.QVisit < 4000:
        post_groups.append("3000 <= x < 4000")
    elif question.QVisit < 5000:
        post_groups.append("4000 <= x < 5000")
    elif question.QVisit < 10000:
        post_groups.append("5000 <= x < 10000")
    elif question.QVisit < 15000:
        post_groups.append("10000 <= x < 15000")
    else:
        post_groups.append("15000 <= x")
    if len(comments) == 0:
        durations.append(0)
        comment_nums.append(0)
    else:
        durations.append(dateTime_to_int(comments[-1].CDate, question.QDate))
        comment_nums.append(len(comments))

d = {'Days': days, 'Duration': durations, 'Comments number': comment_nums, 'Question Visit': post_views, "Question Visit Group": post_groups}
answer  = pd.DataFrame(data=d)

plot_test2(answer)

def plot_test2(data_frame: pd.DataFrame) -> None:
    sns.set_theme(style="white")
    cmap = sns.color_palette("ch:s=.25,rot=-.25", as_cmap=True)
    rel_plot = sns.relplot(x="Days", y="Duration", size="Comments number", hue="Question Visit Group",
                sizes=[3,6,9,12,15,18], alpha=.8, palette=hue_colors,
                height=10, data=data_frame, 
                hue_order=['x < 1000', '1000 <= x < 2000', '2000 <= x < 3000', '3000 <= x < 4000', '4000 <= x < 5000', '5000 <= x < 10000', '10000 <= x < 15000', '15000 <= x'])
    plt.grid()
    plt.show()



"""### New plots:"""

plot_features_year_to_year_scatter_comparison(year_to_year_description, year_to_year_description2, 'number_of_nodes')

plot_features_year_to_year_scatter_comparison(year_to_year_description, year_to_year_description2, 'number_of_edges')

def plot_features_year_to_year_scatter_full_comparison(year_description1: dict, year_description2:dict, feature_name: str) -> None:
    years1 = [year for year in year_description1.keys()]
    years2 = [year for year in year_description2.keys()]
    features = ['number_of_nodes', "number_of_edges"]
    plt.rcParams["figure.figsize"] = [8, 8]
    plt.rcParams['figure.autolayout'] = True
    k = 0
    plt.grid()
    shapes = ['o', '2']
    features1 = [year_description1[year][feature_name] for year in years1]
    features2 = [year_description2[year][feature_name] for year in years2]
    plt.scatter(years1, features1, c='b',marker=shapes[k])
    plt.scatter(years2, features2, c='r', marker=shapes[k])
    k += 1
    coef1 = np.polyfit(years1, features1, 2)
    coef2 = np.polyfit(years2, features2, 2)
    print("First group coefficients:",coef1)
    print("Second group coefficients:", coef2)
    new_x1 = np.linspace(min(years1), max(years1), num=np.size(years1) * 100)
    new_line1 = np.polyval(coef1, new_x1)
    new_x2 = np.linspace(min(years2), max(years2), num=np.size(years2) * 100)
    new_line2 = np.polyval(coef2, new_x2)
    plt.scatter(new_x1,new_line1,c='b', marker='.', s=5)
    plt.scatter(new_x2, new_line2, c="r", marker='.', s=5)
    plt.xlabel("years")
    plt.ylabel(feature_name)
    plt.legend(['First group actual data for number of nodes','Second group actual data for number of nodes', 'First group fitted curve for number of nodes', 'Second group fitted curve number of nodes','First group actual data for number of edges','Second group actual data for number of edges', 'First group fitted curve for number of edges', 'Second group fitted curve number of edges'])
    # plt.legend(loc=2, prop={'size':6})
    plt.savefig(feature_name + '.svg')
    plt.show()

plot_features_year_to_year_scatter_full_comparison(year_to_year_description, year_to_year_description2, 'number_of_nodes')

plot_features_year_to_year_scatter_full_comparison(year_to_year_description, year_to_year_description2, 'number_of_edges')

def plot_features_year_to_year_scatter_full_comparison_centrality(year_description1: dict, year_description2:dict, feature_name: str) -> None:
    years1 = [year for year in year_description1.keys()]
    years2 = [year for year in year_description2.keys()]
    features = ['number_of_nodes', "number_of_edges"]
    plt.rcParams["figure.figsize"] = [8, 8]
    plt.rcParams['figure.autolayout'] = True
    k = 0
    plt.grid()
    shapes = ['o', '2']
    dict1 = [year_description1[year][feature_name] for year in years1]
    dict2 = [year_description2[year][feature_name] for year in years2]
    features1 = []
    features2 = []
    for i in range(len(dict1)):
      answer1 = 0
      n1 = 0
      answer2 = 0
      n2 = 0
      for key in dict1[i].keys():
        answer1 += dict1[i][key]
        n1 += 1
      features1.append(answer1 / n1)
      for key in dict2[i].keys():
        answer2 += dict2[i][key]
        n2 += 1
      features2.append(answer2 / n2)
      
    plt.scatter(years1, features1, c='b',marker=shapes[k])
    plt.scatter(years2, features2, c='r', marker=shapes[k])
    k += 1
    coef1 = np.polyfit(years1, features1, 2)
    coef2 = np.polyfit(years2, features2, 2)
    print("First group coefficients:",coef1)
    print("Second group coefficients:", coef2)
    new_x1 = np.linspace(min(years1), max(years1), num=np.size(years1) * 100)
    new_line1 = np.polyval(coef1, new_x1)
    new_x2 = np.linspace(min(years2), max(years2), num=np.size(years2) * 100)
    new_line2 = np.polyval(coef2, new_x2)
    plt.scatter(new_x1,new_line1,c='darkblue', marker='^', s=5)
    plt.scatter(new_x2, new_line2, c="darkred", marker='^', s=5)
    plt.xlabel("years")
    plt.ylabel(feature_name)
    plt.legend(['First group actual data for number of nodes','Second group actual data for number of nodes', 'First group fitted curve for number of nodes', 'Second group fitted curve number of nodes','First group actual data for number of edges','Second group actual data for number of edges', 'First group fitted curve for number of edges', 'Second group fitted curve number of edges'])
    # plt.legend(loc=2, prop={'size':6})
    plt.savefig(feature_name + '.svg')
    plt.show()

plot_features_year_to_year_scatter_full_comparison_centrality(year_to_year_description, year_to_year_description2, 'degree_centrality')

plot_features_year_to_year_scatter_full_comparison_centrality(year_to_year_description, year_to_year_description2, 'betweenness_centrality')

plot_features_year_to_year_scatter_full_comparison_centrality(year_to_year_description, year_to_year_description2, 'closeness_centrality')

def plot_features_year_to_year_scatter_full_comparison_centrality2(year_description1: dict, year_description2:dict, feature_name: str) -> None:
    years1 = [year for year in year_description1.keys()]
    years2 = [year for year in year_description2.keys()]
    features = ['number_of_nodes', "number_of_edges"]
    plt.rcParams["figure.figsize"] = [8, 8]
    plt.rcParams['figure.autolayout'] = True
    k = 0
    plt.grid()
    shapes = ['o', '2']
    dict1 = [year_description1[year][feature_name] for year in years1]
    dict2 = [year_description2[year][feature_name] for year in years2]
    features1 = []
    features2 = []
    for i in range(len(dict1)):
      answer1 = 0
      n1 = 0
      answer2 = 0
      n2 = 0
      for key in dict1[i].keys():
        answer1 += dict1[i][key]
        n1 += 1
      features1.append(answer1 / n1)
      for key in dict2[i].keys():
        answer2 += dict2[i][key]
        n2 += 1
      features2.append(answer2 / n2)
      
    plt.plot(years1, features1, c='b',marker=shapes[k])
    plt.plot(years2, features2, c='r', marker=shapes[k])
    k += 1
    plt.xlabel("years")
    plt.ylabel(feature_name)
    correct_feature_name = feature_name.split('_')
    correct_feature_name = ' '.join(correct_feature_name)
    plt.legend(['First group actual data for ' + correct_feature_name,'Second group actual data for ' + correct_feature_name])
    # plt.legend(loc=2, prop={'size':6})
    plt.savefig(feature_name + '.svg')
    plt.show()

plot_features_year_to_year_scatter_full_comparison_centrality2(year_to_year_description, year_to_year_description2, 'degree_centrality')

plot_features_year_to_year_scatter_full_comparison_centrality2(year_to_year_description, year_to_year_description2, 'betweenness_centrality')

plot_features_year_to_year_scatter_full_comparison_centrality2(year_to_year_description, year_to_year_description2, 'closeness_centrality')

def plot_features_comparison(year_description1: dict, year_description2: dict, feature_name:str) -> None:
  years = [year for year in year_description1.keys()]
  features1 = [year_description1[year][feature_name] for year in years]
  features2 = [year_description2[year][feature_name] for year in years]
  plt.plot(years, features1, c='b')
  plt.plot(years, features2, c='r')
  plt.grid()
  plt.legend([feature_name + ' in first group', feature_name + 'in second group'])
  plt.xlabel('Years')
  plt.ylabel(feature_name)
  plt.show()

plot_features_comparison(year_to_year_description, year_to_year_description2, 'global_efficiency')

plot_features_comparison(year_to_year_description, year_to_year_description2, 'average_clustering')

def plot_features_year_to_year_scatter_full_comparison_two_axis(year_description1: dict, year_description2:dict) -> None:
    years1 = [year for year in year_description1.keys()]
    years2 = [year for year in year_description2.keys()]
    features = ['number_of_nodes', "number_of_edges"]
    plt.rcParams["figure.figsize"] = [8.0, 8.0]
    plt.rcParams['figure.autolayout'] = True
    k = 0
    shapes = ['o', '2']
    ax1 = plt.subplot()
    ax2 = ax1.twinx()
    for feature_name in features:
      features1 = [year_description1[year][feature_name] for year in years1]
      features2 = [year_description2[year][feature_name] for year in years2]
      if k == 0:
        l11= ax1.scatter(years1, features1, c='#0066ff',marker=shapes[k])
        l12= ax1.scatter(years2, features2, c='#ff5c33', marker=shapes[k])
      else:
        l21= ax2.scatter(years1, features1, c='b',marker=shapes[k])
        l22= ax2.scatter(years2, features2, c='r', marker=shapes[k])
      coef1 = np.polyfit(years1, features1, 2)
      coef2 = np.polyfit(years2, features2, 2)
      print("First group coefficients:",coef1)
      print("Second group coefficients:", coef2)
      new_x1 = np.linspace(min(years1), max(years1), num=np.size(years1) * 100)
      new_line1 = np.polyval(coef1, new_x1)
      new_x2 = np.linspace(min(years2), max(years2), num=np.size(years2) * 100)
      new_line2 = np.polyval(coef2, new_x2)
      if k == 0:
        l13= ax1.scatter(new_x1,new_line1,c='#0066ff', marker='^', s=5)
        l14= ax1.scatter(new_x2, new_line2, c="#ff5c33", marker='p', s=5)
      else:
        l23= ax2.scatter(new_x1,new_line1,c='darkblue', marker='^', s=5)
        l24= ax2.scatter(new_x2, new_line2, c="darkred", marker='p', s=5)
      k += 1
    ax1.set_xlabel("years")
    ax1.set_ylabel("Number of Nodes")
    ax2.set_ylabel("Number of Edges")
    plt.legend([l11, l12, l13, l14, l21, l22, l23, l24], ['First group actual data for number of nodes','Second group actual data for number of nodes', 'First group fitted curve for number of nodes', 'Second group fitted curve number of nodes','First group actual data for number of edges','Second group actual data for number of edges', 'First group fitted curve for number of edges', 'Second group fitted curve number of edges'])
    # plt.legend(prop={'size':6})
    plt.savefig("Nodes-Edges.svg")
    plt.show()

def plot_features_comparison_two_axis(year_description1: dict, year_description2: dict) -> None:
  years = [year for year in year_description1.keys()]
  plt.rcParams["figure.figsize"] = [8, 8]
  plt.rcParams['figure.autolayout'] = True
  ax1 = plt.subplot()
  ax2 = ax1.twinx()
  features_names = ["global_efficiency", "average_clustering"]
  k = 0
  for feature_name in features_names:
    features1 = [year_description1[year][feature_name] for year in years]
    features2 = [year_description2[year][feature_name] for year in years]
    if k == 0:
      l11, = ax1.plot(years, features1, c='b')
      l12, = ax1.plot(years, features2, c='r')
    else:
      l21, =ax2.plot(years, features1, c='#0066ff')
      l22, =ax2.plot(years, features2, c='#ff5c33')
    k += 1
  
  ax1.set_xlabel('Years')
  ax1.set_ylabel("Global Efficiency")
  ax2.set_ylabel("Average Clustering")
  plt.legend([l11, l12, l21, l22], ["First group global efficiency", "Second group global efficiency", "First group average clustering", "Second group average clustering"], fontsize=8, loc=4)
  plt.savefig("Global-Average.svg")
  plt.show()

plot_features_year_to_year_scatter_full_comparison_two_axis(year_to_year_description, year_to_year_description2)

plot_features_comparison_two_axis(year_to_year_description, year_to_year_description2)

plot_4D_Questions(graphAnalysis.get_questions_data_frame())

data_frame1 = graphAnalysis.get_questions_data_frame()

data_frame1

data_frame1["Question Visit"]

data_frame1["Question Visit"] = np.log(data_frame1["Question Visit"])
for i in range(len(data_frame1["Comments number"])):
  if data_frame1["Comments number"][i] != 0:
    data_frame1["Comments number"][i] = np.log(data_frame1["Comments number"][i])

plot_4D_Questions(data_frame1)

data_frame2 = graphAnalysis2.get_questions_data_frame()

data_frame2

data_frame2["Question Visit"] = np.log(data_frame2["Question Visit"])
for i in range(len(data_frame2["Comments number"])):
  if data_frame2["Comments number"][i] != 0:
    data_frame2["Comments number"][i] = np.log(data_frame2["Comments number"][i])

plot_4D_Questions(data_frame2)

data_frame1 = graphAnalysis.get_users_data_frame()

data_frame1

for i in range(len(data_frame1["Post counts"])):
  if data_frame1["Post counts"][i] != 0:
    data_frame1["Post counts"][i] = np.log(data_frame1["Post counts"][i])

plot_4D_Users(data_frame1)

